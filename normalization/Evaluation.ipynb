{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikelsegura/fstvsicl/blob/main/normalization/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate -q\n",
        "!pip install tabulate -q\n",
        "\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "import os\n",
        "from evaluate import load\n",
        "from tabulate import tabulate\n",
        "try:\n",
        "    import jiwer\n",
        "except ImportError:\n",
        "    !pip install jiwer -q"
      ],
      "metadata": {
        "id": "p1qLi5IW9G9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_url = \"https://github.com/MCL-Lab-mx/fstvsicl.git\"\n",
        "!git clone {repo_url}\n",
        "\n",
        "%cd fstvsicl\n",
        "\n",
        "BASE_PATH = \"otomi/\"\n",
        "OUTPUT_PATH = \"otomi/colab_eval/\"\n",
        "!mkdir -p {OUTPUT_PATH}"
      ],
      "metadata": {
        "id": "KLjsohujp6Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbf5ce2-de24-40e7-8ab4-c98b565774a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fstvsicl'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 96 (delta 62), reused 75 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (96/96), 723.10 KiB | 10.04 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/fstvsicl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WER & CER"
      ],
      "metadata": {
        "id": "DdgWm3ML_L9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_file_path = f'{BASE_PATH}test_set.tsv'\n",
        "reference_df = pd.read_csv(reference_file_path, sep='\\t')\n",
        "inali_reference = reference_df['INALI'].str.lower().tolist()\n",
        "\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "experiment_folder_path = f'{BASE_PATH}clean_results/'\n",
        "\n",
        "results = []\n",
        "\n",
        "# Iterate through each experiment TSV file\n",
        "for file_name in os.listdir(experiment_folder_path):\n",
        "    if file_name.endswith('.tsv') and file_name != 'test_set.tsv':\n",
        "        file_path = os.path.join(experiment_folder_path, file_name)\n",
        "        experiment_df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "        result_column = experiment_df['Result'].str.lower().tolist()\n",
        "\n",
        "        input_column = experiment_df['Input'].str.lower().tolist()\n",
        "\n",
        "        # Compute WER and CER for Result Column\n",
        "        wer_score = wer_metric.compute(predictions=result_column, references=inali_reference)\n",
        "        cer_score = cer_metric.compute(predictions=result_column, references=inali_reference)\n",
        "\n",
        "        # Compute WER and CER for Result Column\n",
        "        wer_baseline = wer_metric.compute(predictions=input_column, references=inali_reference)\n",
        "        cer_baseline = cer_metric.compute(predictions=input_column, references=inali_reference)\n",
        "\n",
        "        # Convert scores to percentages\n",
        "        wer_percentage = wer_score * 100\n",
        "        cer_percentage = cer_score * 100\n",
        "\n",
        "        wer_baseline_percentage = wer_baseline * 100\n",
        "        cer_baseline_percentage = cer_baseline * 100\n",
        "\n",
        "        results.append([file_name.lower(), f\"{wer_percentage:.2f}%\", f\"{wer_baseline_percentage:.2f}%\", f\"{cer_percentage:.2f}%\", f\"{cer_baseline_percentage:.2f}%\"])  # Convert file name to lowercase\n",
        "\n",
        "results_sorted = sorted(results, key=lambda x: x[0])\n",
        "\n",
        "headers = [\"Experiment File\", \"WER Score\", \"WER Baseline\",\"CER Score\", \"CER baseline\"]\n",
        "print(tabulate(results_sorted, headers=headers, tablefmt=\"pretty\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js2z4MpUe8R3",
        "outputId": "842a4edf-d943-4192-f8ca-a9fe31c63d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------+-----------+--------------+-----------+--------------+\n",
            "|               Experiment File               | WER Score | WER Baseline | CER Score | CER baseline |\n",
            "+---------------------------------------------+-----------+--------------+-----------+--------------+\n",
            "|             fst_otq_results.tsv             |   4.36%   |    0.10%     |   2.03%   |    0.04%     |\n",
            "|           fst_ots_otq_results.tsv           |  10.78%   |    7.74%     |   3.37%   |    1.59%     |\n",
            "|             fst_ots_results.tsv             |  20.27%   |    18.90%    |   5.31%   |    4.09%     |\n",
            "|   gpt_3_5_turbo_few_shot_otq_results.tsv    |   0.34%   |    0.10%     |   0.10%   |    0.04%     |\n",
            "| gpt_3_5_turbo_few_shot_ots_otq_results.tsv  |   7.06%   |    7.74%     |   1.61%   |    1.59%     |\n",
            "|   gpt_3_5_turbo_few_shot_ots_results.tsv    |  14.34%   |    18.90%    |   3.45%   |    4.09%     |\n",
            "|   gpt_3_5_turbo_zero_shot_otq_results.tsv   |  12.34%   |    0.10%     |   3.13%   |    0.04%     |\n",
            "| gpt_3_5_turbo_zero_shot_ots_otq_results.tsv |  13.93%   |    7.74%     |   3.28%   |    1.59%     |\n",
            "|   gpt_3_5_turbo_zero_shot_ots_results.tsv   |  24.86%   |    18.90%    |   6.48%   |    4.09%     |\n",
            "|       gpt_4o_few_shot_otq_results.tsv       |   0.84%   |    0.10%     |   0.21%   |    0.04%     |\n",
            "|     gpt_4o_few_shot_ots_otq_results.tsv     |   6.15%   |    7.74%     |   1.36%   |    1.59%     |\n",
            "|       gpt_4o_few_shot_ots_results.tsv       |  11.35%   |    18.90%    |   2.68%   |    4.09%     |\n",
            "|      gpt_4o_zero_shot_otq_results.tsv       |  19.29%   |    0.10%     |   6.22%   |    0.04%     |\n",
            "|    gpt_4o_zero_shot_ots_otq_results.tsv     |  23.36%   |    7.74%     |   7.11%   |    1.59%     |\n",
            "|      gpt_4o_zero_shot_ots_results.tsv       |  31.58%   |    18.90%    |  10.17%   |    4.09%     |\n",
            "|   llama_3_1_70b_few_shot_otq_results.tsv    |   0.39%   |    0.10%     |   0.09%   |    0.04%     |\n",
            "| llama_3_1_70b_few_shot_ots_otq_results.tsv  |   8.65%   |    7.74%     |   2.16%   |    1.59%     |\n",
            "|   llama_3_1_70b_few_shot_ots_results.tsv    |  14.56%   |    18.90%    |   3.51%   |    4.09%     |\n",
            "|   llama_3_1_70b_zero_shot_otq_results.tsv   |  17.67%   |    0.10%     |   8.02%   |    0.04%     |\n",
            "| llama_3_1_70b_zero_shot_ots_otq_results.tsv |  20.40%   |    7.74%     |   5.29%   |    1.59%     |\n",
            "|   llama_3_1_70b_zero_shot_ots_results.tsv   |  29.82%   |    18.90%    |   8.85%   |    4.09%     |\n",
            "|   llama_3_3_70b_few_shot_otq_results.tsv    |   0.24%   |    0.10%     |   0.07%   |    0.04%     |\n",
            "| llama_3_3_70b_few_shot_ots_otq_results.tsv  |   8.49%   |    7.74%     |   2.10%   |    1.59%     |\n",
            "|   llama_3_3_70b_few_shot_ots_results.tsv    |  15.53%   |    18.90%    |   3.74%   |    4.09%     |\n",
            "|   llama_3_3_70b_zero_shot_otq_results.tsv   |  17.94%   |    0.10%     |   5.22%   |    0.04%     |\n",
            "| llama_3_3_70b_zero_shot_ots_otq_results.tsv |  25.65%   |    7.74%     |   7.44%   |    1.59%     |\n",
            "|   llama_3_3_70b_zero_shot_ots_results.tsv   |  30.62%   |    18.90%    |   9.09%   |    4.09%     |\n",
            "+---------------------------------------------+-----------+--------------+-----------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_file_path = f'{BASE_PATH}test_set.tsv'\n",
        "reference_df = pd.read_csv(reference_file_path, sep='\\t')\n",
        "\n",
        "inali_reference = reference_df['INALI'].astype(str).str.lower().tolist()\n",
        "\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "experiment_folder_path = f'{BASE_PATH}clean_results/'\n",
        "output_file_path = f'{OUTPUT_PATH}oto_eval_per_sentence.tsv'\n",
        "\n",
        "results = []\n",
        "\n",
        "# Iterate through each experiment TSV file\n",
        "for file_name in os.listdir(experiment_folder_path):\n",
        "    print(\"- evaluating \"+file_name)\n",
        "    if file_name.endswith('.tsv') and file_name != 'test_set.tsv':\n",
        "        file_path = os.path.join(experiment_folder_path, file_name)\n",
        "        experiment_df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "        if 'Result' not in experiment_df:\n",
        "            print(f\"Skipping {file_name}: 'Result' column not found.\")\n",
        "            continue\n",
        "\n",
        "        input_column = experiment_df['Input'].tolist()\n",
        "\n",
        "        result_column = experiment_df['Result'].astype(str).str.lower().fillna(\"\").tolist()\n",
        "\n",
        "        # Compute WER and CER for each sentence pair\n",
        "        for ref, pred, input in zip(inali_reference, result_column, input_column):\n",
        "            if not pred.strip():\n",
        "                print(f\"Skipping empty prediction in {file_name}\")\n",
        "                continue\n",
        "\n",
        "            wer_score = wer_metric.compute(predictions=[pred], references=[ref])\n",
        "            cer_score = cer_metric.compute(predictions=[pred], references=[ref])\n",
        "\n",
        "            results.append([input, pred, ref, f\"{wer_score * 100:.2f}%\", f\"{cer_score * 100:.2f}%\", file_name.lower()])\n",
        "\n",
        "output_df = pd.DataFrame(results, columns=[\"INPUT\", \"PREDICTION\", \"INALI_REFERENCE\", \"WER\", \"CER\", \"FILE\"])\n",
        "output_df.to_csv(output_file_path, sep='\\t', index=False)\n",
        "print(f\"Results saved to: {output_file_path}\")"
      ],
      "metadata": {
        "id": "YFHqIkPtCNJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31112417-ca3b-4ac5-b3b7-087b11e13988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- evaluating llama_3_1_70b_zero_shot_OTS_results.tsv\n",
            "- evaluating fst_OTQ_results.tsv\n",
            "- evaluating llama_3_1_70b_few_shot_OTS_results.tsv\n",
            "- evaluating gpt_4o_zero_shot_OTS_OTQ_results.tsv\n",
            "- evaluating llama_3_3_70b_zero_shot_OTS_OTQ_results.tsv\n",
            "- evaluating gpt_3_5_turbo_few_shot_OTS_results.tsv\n",
            "- evaluating llama_3_1_70b_zero_shot_OTS_OTQ_results.tsv\n",
            "- evaluating llama_3_1_70b_few_shot_OTS_OTQ_results.tsv\n",
            "- evaluating llama_3_1_70b_zero_shot_OTQ_results.tsv\n",
            "- evaluating llama_3_3_70b_few_shot_OTQ_results.tsv\n",
            "- evaluating gpt_3_5_turbo_zero_shot_OTQ_results.tsv\n",
            "- evaluating gpt_4o_few_shot_OTS_results.tsv\n",
            "- evaluating gpt_3_5_turbo_few_shot_OTQ_results.tsv\n",
            "- evaluating gpt_4o_few_shot_OTQ_results.tsv\n",
            "- evaluating llama_3_3_70b_few_shot_OTS_OTQ_results.tsv\n",
            "- evaluating llama_3_3_70b_few_shot_OTS_results.tsv\n",
            "- evaluating gpt_3_5_turbo_zero_shot_OTS_results.tsv\n",
            "- evaluating fst_OTS_OTQ_results.tsv\n",
            "- evaluating llama_3_3_70b_zero_shot_OTS_results.tsv\n",
            "- evaluating gpt_4o_zero_shot_OTS_results.tsv\n",
            "- evaluating gpt_3_5_turbo_zero_shot_OTS_OTQ_results.tsv\n",
            "- evaluating gpt_3_5_turbo_few_shot_OTS_OTQ_results.tsv\n",
            "- evaluating gpt_4o_zero_shot_OTQ_results.tsv\n",
            "- evaluating gpt_4o_few_shot_OTS_OTQ_results.tsv\n",
            "- evaluating llama_3_1_70b_few_shot_OTQ_results.tsv\n",
            "- evaluating llama_3_3_70b_zero_shot_OTQ_results.tsv\n",
            "- evaluating fst_OTS_results.tsv\n",
            "Results saved to: otomi/colab_eval/oto_eval_per_sentence.tsv\n"
          ]
        }
      ]
    }
  ]
}