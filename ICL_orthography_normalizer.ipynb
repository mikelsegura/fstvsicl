{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikelsegura/fstvsicl/blob/main/ICL_orthography_normalizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH0qKJZs4E0i"
      },
      "source": [
        "# N-Shot Learning Experiment Notebook\n",
        "\n",
        "This notebook demonstrates a zero-shot and few-shot learning experiment for orthographic standardization tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX3_7LMa4E0j"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9tN2WbQ4E0j"
      },
      "outputs": [],
      "source": [
        "!pip install -q tiktoken\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "import time\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFM24gPG4E0k"
      },
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set up the path for data files and initialize API client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO0qzBN_4E0k",
        "outputId": "6f1a7d3f-0b33-4ec4-f368-79cd8f0e15cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fstvsicl'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 102 (delta 63), reused 75 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (102/102), 726.53 KiB | 11.53 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "/content/fstvsicl/fstvsicl\n"
          ]
        }
      ],
      "source": [
        "repo_url = \"https://github.com/MCL-Lab-mx/fstvsicl.git\"\n",
        "\n",
        "!git clone {repo_url}\n",
        "\n",
        "%cd fstvsicl\n",
        "\n",
        "BASE_PATH = \"otomi/\"\n",
        "OUTPUT_PATH = \"otomi/colab_outputs/\"\n",
        "!mkdir -p {OUTPUT_PATH}\n",
        "\n",
        "client_gpt = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "client_llama = OpenAI(api_key = userdata.get('LLAMA_API_KEY'), base_url = \"https://api.llamaapi.com\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_84UO2Yk4E0l"
      },
      "source": [
        "## 3. Helper Functions\n",
        "\n",
        "### 3.1 Formatting Few-Shot Examples\n",
        "\n",
        "This function takes source and target sentences and formats them into a prompt using a template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1Shezbb4E0l"
      },
      "outputs": [],
      "source": [
        "def format_few_shot_examples(\n",
        "    support_set,\n",
        "    num_examples,\n",
        "    instruction_template,\n",
        "    source_column=\"SOURCE\",\n",
        "    target_column=\"TARGET\"\n",
        "):\n",
        "    source_sentences = support_set[source_column].values\n",
        "    target_sentences = support_set[target_column].values\n",
        "    \"\"\"Formats few-shot examples into a prompt using dynamic column names.\"\"\"\n",
        "    examples = \"\".join(\n",
        "        f\"{i+1}. {source_column}: {source_sentences[i]}\\n\"\n",
        "        f\"{target_column}: {target_sentences[i]}\\n\\n\"\n",
        "        for i in range(num_examples)\n",
        "    )\n",
        "    return instruction_template.replace(\"{examples}\", examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IJP5y804E0l"
      },
      "source": [
        "### 3.2 Calling the Model\n",
        "\n",
        "This function sends the prompt to the API Client and returns the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vravjOtA4E0l"
      },
      "outputs": [],
      "source": [
        "def call_model(prompt, model_name, model_client, temperature):\n",
        "    response = model_client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        temperature=temperature,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrdyqBTM4E0l"
      },
      "source": [
        "## 4. Main Experiment Function\n",
        "\n",
        "This function runs either zero-shot or few-shot experiments:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prices are expressed per 1,000,000 tokens\n",
        "MODEL_PRICING = {\n",
        "    \"gpt-3.5-turbo\": {\"prompt\": 1.5, \"completion\": 2.0},\n",
        "    \"gpt-4o\": {\"prompt\": 2.5, \"completion\": 10.0},\n",
        "    \"llama3.3-70b\": {\"prompt\": 2.8, \"completion\": 2.8},\n",
        "    \"llama3.1-70b\": {\"prompt\": 2.8, \"completion\": 2.8},\n",
        "}\n"
      ],
      "metadata": {
        "id": "MEk4SMWNh4s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCGLKSxl4E0m"
      },
      "outputs": [],
      "source": [
        "def run_experiment(\n",
        "    language,\n",
        "    experiment_type,\n",
        "    model_name,\n",
        "    model_client,\n",
        "    test_set,\n",
        "    support_set=None,\n",
        "    source_column=\"SOURCE\",\n",
        "    target_column=\"TARGET\",\n",
        "    num_few_shot_examples=0,\n",
        "    instruction_template=\"\",\n",
        "    temperature=0.2,\n",
        "    num_retries=3,\n",
        "    quiet=False\n",
        "):\n",
        "    \"\"\"Runs a zero-shot or few-shot experiment, retries on API failures,\n",
        "    auto-counts tokens for cost, and saves results & logs cost.\"\"\"\n",
        "    # prepare tokenizer for local token counting\n",
        "    try:\n",
        "        encoder = tiktoken.encoding_for_model(model_name)\n",
        "    except KeyError:\n",
        "        encoder = tiktoken.get_encoding(\"cl100k_base\")  # fallback\n",
        "\n",
        "    test_sentences = test_set[source_column].values\n",
        "\n",
        "    # prepare few-shot instruction if needed\n",
        "    if experiment_type == \"few-shot\" and support_set is not None:\n",
        "        instruction = format_few_shot_examples(\n",
        "            support_set,\n",
        "            num_few_shot_examples,\n",
        "            instruction_template,\n",
        "            source_column,\n",
        "            target_column\n",
        "        )\n",
        "    else:\n",
        "        instruction = instruction_template\n",
        "\n",
        "    results = []\n",
        "    total_cost = 0.0\n",
        "\n",
        "    for i, test_sentence in enumerate(test_sentences, 1):\n",
        "        # construct prompt with dynamic labels\n",
        "        prompt = f\"{instruction}{source_column}: {test_sentence}\\n\\n{target_column}: [Your prediction here]\"\n",
        "\n",
        "        # retry logic for unstable API calls\n",
        "        attempt = 0\n",
        "        while True:\n",
        "            try:\n",
        "                response = call_model(\n",
        "                    prompt,\n",
        "                    model_name,\n",
        "                    model_client,\n",
        "                    temperature\n",
        "                )\n",
        "                break\n",
        "            except Exception as e:\n",
        "                attempt += 1\n",
        "                if attempt >= num_retries:\n",
        "                    print(f\"Iteration {i}: Failed after {num_retries} attempts. Error: {e}\")\n",
        "                    raise\n",
        "                wait_time = 2 ** (attempt - 1)\n",
        "                print(f\"API call failed (attempt {attempt}/{num_retries}), retrying in {wait_time}s...\")\n",
        "                time.sleep(wait_time)\n",
        "\n",
        "        # extract generated text\n",
        "        if isinstance(response, dict):\n",
        "            try:\n",
        "                result_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "            except KeyError:\n",
        "                result_text = response[\"choices\"][0][\"text\"]\n",
        "        else:\n",
        "            result_text = response\n",
        "\n",
        "        # local token counting for cost\n",
        "        prompt_tokens = len(encoder.encode(prompt))\n",
        "        result_tokens = len(encoder.encode(result_text))\n",
        "\n",
        "        # compute cost\n",
        "        rates = MODEL_PRICING.get(model_name, {})\n",
        "        cost = (prompt_tokens / 1_000_000) * rates.get(\"prompt\", 0.0) + \\\n",
        "               (result_tokens / 1_000_000) * rates.get(\"completion\", 0.0)\n",
        "        total_cost += cost\n",
        "        results.append([test_sentence, result_text])\n",
        "\n",
        "        if not quiet:\n",
        "            print(\n",
        "                f\"Iteration {i}:\\n\"\n",
        "                f\"{source_column} = {test_sentence}\\n\"\n",
        "                f\"{target_column} = {result_text}\\n\"\n",
        "                f\"Cost = ${cost:.6f}\\n\"\n",
        "            )\n",
        "        else:\n",
        "            print(f\"\\r{i}/{len(test_sentences)}\", end=\"\")\n",
        "\n",
        "    # save results\n",
        "    output_filename = f\"{language}_{model_name}_{experiment_type}_{source_column}_{target_column}\"\n",
        "    df_results = pd.DataFrame(results, columns=[source_column, target_column])\n",
        "    out_path = f\"{OUTPUT_PATH}{output_filename}.tsv\"\n",
        "    df_results.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "    print(f\"\\nExperiment results saved to '{out_path}'.\")\n",
        "\n",
        "    # log total cost\n",
        "    cost_entry = (\n",
        "        f\"{datetime.now().isoformat()}\\t{experiment_type}\\t{model_name}\\t\"\n",
        "        f\"{output_filename}\\t${total_cost:.6f}\\n\"\n",
        "    )\n",
        "    with open(f\"{BASE_PATH}costs.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(cost_entry)\n",
        "    print(f\"Total cost: ${total_cost:.6f} (logged in costs.txt)\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feE2wjNl4E0m"
      },
      "source": [
        "## 5. Loading Data\n",
        "\n",
        "Load the test and support datasets from TSV files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTrtL3wC4E0m"
      },
      "outputs": [],
      "source": [
        "df_test_set = pd.read_csv(f\"{BASE_PATH}test_set.tsv\", sep=\"\\t\")\n",
        "df_support_set = pd.read_csv(f\"{BASE_PATH}support_set.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4JI9zv64E0m"
      },
      "source": [
        "## 6. Running Experiments\n",
        "\n",
        "### 6.1 Zero-Shot Experiment\n",
        "\n",
        "This runs without any examples, just with instructions:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_full_prompt(\n",
        "    test_sentence,\n",
        "    support_set=None,\n",
        "    num_few_shot_examples=0,\n",
        "    instruction_template=\"\",\n",
        "    source_column=\"SOURCE\",\n",
        "    target_column=\"TARGET\"\n",
        "):\n",
        "    \"\"\"Builds the full prompt that would be sent to the model,\n",
        "    including few-shot examples if provided.\"\"\"\n",
        "\n",
        "    # prepare instruction\n",
        "    if support_set is not None and num_few_shot_examples > 0:\n",
        "        instruction = format_few_shot_examples(\n",
        "            support_set,\n",
        "            num_few_shot_examples,\n",
        "            instruction_template,\n",
        "            source_column,\n",
        "            target_column\n",
        "        )\n",
        "    else:\n",
        "        instruction = instruction_template\n",
        "\n",
        "    # full final prompt\n",
        "    prompt = (\n",
        "        f\"{instruction}\"\n",
        "        f\"{source_column}: {test_sentence}\\n\\n\"\n",
        "        f\"{target_column}: [Your prediction here]\"\n",
        "    )\n",
        "\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "Dgb1V9EkgrXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: print all prompts for a given config\n",
        "def print_zero_shot_prompts(test_set, source_column, target_column, instruction_template):\n",
        "    for sentence in test_set[source_column].head(N):\n",
        "        prompt = build_full_prompt(\n",
        "            test_sentence=sentence,\n",
        "            support_set=None,  # zero-shot\n",
        "            num_few_shot_examples=0,\n",
        "            instruction_template=instruction_template,\n",
        "            source_column=source_column,\n",
        "            target_column=target_column\n",
        "        )\n",
        "        print(prompt)\n",
        "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# 1. OTQ → OTS\n",
        "print(\"### OTQ → OTS ###\\n\")\n",
        "print_zero_shot_prompts(\n",
        "    test_set=df_test_set,\n",
        "    source_column=\"OTQ\",\n",
        "    target_column=\"OTS\",\n",
        "    instruction_template=\"\"\"Predict the OTS orthographic standardization (State of Mexico Otomi) for the following Otomi sentence written in the OTQ standard (Queretaro Otomi) (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\n\"\"\"\n",
        ")\n",
        "\n",
        "# 2. INALI → OTS\n",
        "print(\"### INALI → OTS ###\\n\")\n",
        "print_zero_shot_prompts(\n",
        "    test_set=df_test_set,\n",
        "    source_column=\"INALI\",\n",
        "    target_column=\"OTS\",\n",
        "    instruction_template=\"\"\"Predict the OTS orthographic standardization (State of Mexico Otomi) for the following Otomi sentence written in the INALI standard (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\n\"\"\"\n",
        ")\n",
        "\n",
        "# 3. OTS → OTQ\n",
        "print(\"### OTS → OTQ ###\\n\")\n",
        "print_zero_shot_prompts(\n",
        "    test_set=df_test_set,\n",
        "    source_column=\"OTS\",\n",
        "    target_column=\"OTQ\",\n",
        "    instruction_template=\"\"\"Predict the OTQ orthographic standardization (Queretaro Otomi) for the following Otomi sentence written in the OTS standard (State of Mexico Otomi) (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\n\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "JjlmzdDPxOgR",
        "outputId": "689d07a8-e0cf-4bd0-b41e-e64bec24ecc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### OTQ → OTS ###\n",
            "\n",
            "Predict the OTS orthographic standardization (State of Mexico Otomi) for the following Otomi sentence written in the OTQ standard (Queretaro Otomi) (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "OTQ: -pasadores: \"ya nts'äza xi mra nts'u̱t'i mi t'e̱ni ko n'a ra t'e̱nga ts'u̱t'a bo̱ja mi thutuabi ra ballesta\".\n",
            "\n",
            "OTS: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "### INALI → OTS ###\n",
            "\n",
            "Predict the OTS orthographic standardization (State of Mexico Otomi) for the following Otomi sentence written in the INALI standard (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "INALI: -pasadores: \"ya nts'äza xi mra nts'u̱t'i mi t'e̱ni ko n'a ra t'e̱nga ts'u̱t'a bo̱ja mi thutuabi ra ballesta\".\n",
            "\n",
            "OTS: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "### OTS → OTQ ###\n",
            "\n",
            "Predict the OTQ orthographic standardization (Queretaro Otomi) for the following Otomi sentence written in the OTS standard (State of Mexico Otomi) (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "OTS: -pasadores: \"ya nts'äza xi mra nts'u̱t'i mi t'e̱ni ko n'a ra t'e̱nga ts'u̱t'a bo̱kja mi tjutuabi ra ballesta\".\n",
            "\n",
            "OTQ: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    (\"gpt-3.5-turbo\", client_gpt),\n",
        "    (\"gpt-4o\", client_gpt),\n",
        "    (\"llama3.1-70b\", client_llama),\n",
        "    (\"llama3.3-70b\", client_llama)\n",
        "]\n",
        "\n",
        "for model, client in models:\n",
        "\n",
        "  run_experiment(\n",
        "      language=\"oto\",\n",
        "      experiment_type=\"zero-shot\",\n",
        "      model_name=model,\n",
        "      model_client=client,\n",
        "      test_set=df_test_set,\n",
        "      source_column=\"OTQ\",\n",
        "      target_column=\"OTS\",\n",
        "      instruction_template=\"\"\"Predict the OTS orthographic standardization (State of Mexico Otomi) for the following Otomi sentence written in the OTQ standard (Queretaro Otomi) (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\n\"\"\",\n",
        "      quiet = True\n",
        "  )\n",
        "\n",
        "  run_experiment(\n",
        "      language=\"oto\",\n",
        "      experiment_type=\"zero-shot\",\n",
        "      model_name=model,\n",
        "      model_client=client,\n",
        "      test_set=df_test_set,\n",
        "      source_column=\"INALI\",\n",
        "      target_column=\"OTS\",\n",
        "      instruction_template=\"\"\"Predict the OTS orthographic standardization (State of Mexico Otomi) for the following Otomi sentence written in the INALI standard (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\n\"\"\",\n",
        "      quiet = True\n",
        "  )\n",
        "\n",
        "  run_experiment(\n",
        "      language=\"oto\",\n",
        "      experiment_type=\"zero-shot\",\n",
        "      model_name=model,\n",
        "      model_client=client,\n",
        "      test_set=df_test_set,\n",
        "      source_column=\"OTS\",\n",
        "      target_column=\"OTQ\",\n",
        "      instruction_template=\"\"\"Predict the OTQ orthographic standardization (Queretaro Otomi) for the following Otomi sentence written in the OTS standard (State of Mexico Otomi) (please return only the normalized sentences, no explanations). Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\n\"\"\",\n",
        "      quiet = True\n",
        "  )"
      ],
      "metadata": {
        "id": "0QgsK5QVVrFg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnQpzYtf4E0m"
      },
      "source": [
        "### 6.2 Few-Shot Experiment\n",
        "\n",
        "This runs with 10 examples from the support set:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview first N test sentences from each source column\n",
        "N = 2\n",
        "\n",
        "# Helper: print all prompts for a given config (few-shot)\n",
        "def print_few_shot_prompts(\n",
        "    test_set, support_set,\n",
        "    source_column, target_column,\n",
        "    num_few_shot_examples,\n",
        "    instruction_template\n",
        "):\n",
        "    for sentence in test_set[source_column].head(N):\n",
        "        prompt = build_full_prompt(\n",
        "            test_sentence=sentence,\n",
        "            support_set=support_set,\n",
        "            num_few_shot_examples=num_few_shot_examples,\n",
        "            instruction_template=instruction_template,\n",
        "            source_column=source_column,\n",
        "            target_column=target_column\n",
        "        )\n",
        "        print(prompt)\n",
        "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# 1. OTQ → OTS\n",
        "print(\"### OTQ → OTS ###\\n\")\n",
        "print_few_shot_prompts(\n",
        "    test_set=df_test_set,\n",
        "    support_set=df_support_set,\n",
        "    source_column=\"OTQ\",\n",
        "    target_column=\"OTS\",\n",
        "    num_few_shot_examples=N,\n",
        "    instruction_template=\"\"\"Below are examples of orthographic conversions of strings from the OTQ standard (Queretaro Otomi) to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\nExamples:\\n\\n{examples}Task:\\n\\nUsing these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\\n\\n\"\"\"\n",
        ")\n",
        "\n",
        "# 2. INALI → OTS\n",
        "print(\"### INALI → OTS ###\\n\")\n",
        "print_few_shot_prompts(\n",
        "    test_set=df_test_set,\n",
        "    support_set=df_support_set,\n",
        "    source_column=\"INALI\",\n",
        "    target_column=\"OTS\",\n",
        "    num_few_shot_examples=N,\n",
        "    instruction_template=\"\"\"Below are examples of orthographic conversions of strings from the INALI standard to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\nExamples:\\n\\n{examples}Task:\\n\\nUsing these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\\n\\n\"\"\"\n",
        ")\n",
        "\n",
        "# 3. OTS → OTQ\n",
        "print(\"### OTS → OTQ ###\\n\")\n",
        "print_few_shot_prompts(\n",
        "    test_set=df_test_set,\n",
        "    support_set=df_support_set,\n",
        "    source_column=\"OTS\",\n",
        "    target_column=\"OTQ\",\n",
        "    num_few_shot_examples=N,\n",
        "    instruction_template=\"\"\"Below are examples of orthographic conversions of strings from the OTS standard (State of Mexico Otomi) to the OTQ standard (Queretaro Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\nExamples:\\n\\n{examples}Task:\\n\\nUsing these examples as a guide, predict the OTQ orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\\n\\n\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "g7E_8gV6x3XG",
        "outputId": "993f290e-ed47-41df-cc2d-9547c37b4632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### OTQ → OTS ###\n",
            "\n",
            "Below are examples of orthographic conversions of strings from the OTQ standard (Queretaro Otomi) to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "Examples:\n",
            "\n",
            "1. OTQ: r'atsa noya ra sahagún: ndäxjua k'oi florentino. he̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "OTS: r'atsa noya ra sahagún: ndäxkjua k'oi florentino. je̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "\n",
            "2. OTQ: nubia ri nt'ode nehe mar'a ya ñ'o̱ho̱ ne ya b'e̱hña ndeznä: ha ra yancuic tlahtolli, r'ayo noya.\n",
            "OTS: nubia ri nt'ode neje mar'a ya ñ'o̱jo̱ ne ya b'e̱jña ndeznä: ja ra yancuic tlahtolli, r'ayo noya.\n",
            "\n",
            "Task:\n",
            "\n",
            "Using these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\n",
            "\n",
            "OTQ: -pasadores: \"ya nts'äza xi mra nts'u̱t'i mi t'e̱ni ko n'a ra t'e̱nga ts'u̱t'a bo̱ja mi thutuabi ra ballesta\".\n",
            "\n",
            "OTS: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Below are examples of orthographic conversions of strings from the OTQ standard (Queretaro Otomi) to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "Examples:\n",
            "\n",
            "1. OTQ: r'atsa noya ra sahagún: ndäxjua k'oi florentino. he̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "OTS: r'atsa noya ra sahagún: ndäxkjua k'oi florentino. je̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "\n",
            "2. OTQ: nubia ri nt'ode nehe mar'a ya ñ'o̱ho̱ ne ya b'e̱hña ndeznä: ha ra yancuic tlahtolli, r'ayo noya.\n",
            "OTS: nubia ri nt'ode neje mar'a ya ñ'o̱jo̱ ne ya b'e̱jña ndeznä: ja ra yancuic tlahtolli, r'ayo noya.\n",
            "\n",
            "Task:\n",
            "\n",
            "Using these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\n",
            "\n",
            "OTQ: cantares mexicanos, biblioteca nacional de méxico, ya nt'ofo 1628 bis, folio 16 v.\n",
            "\n",
            "OTS: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "### INALI → OTS ###\n",
            "\n",
            "Below are examples of orthographic conversions of strings from the INALI standard to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "Examples:\n",
            "\n",
            "1. INALI: r'atsa noya ra sahagún: ndäxjua k'oi florentino. he̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "OTS: r'atsa noya ra sahagún: ndäxkjua k'oi florentino. je̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "\n",
            "2. INALI: nubia ri nt'ode nehe mar'a ya ñ'o̱ho̱ ne ya b'e̱hña ndeznä: ha ra yancuic tlahtolli, r'ayo noya.\n",
            "OTS: nubia ri nt'ode neje mar'a ya ñ'o̱jo̱ ne ya b'e̱jña ndeznä: ja ra yancuic tlahtolli, r'ayo noya.\n",
            "\n",
            "Task:\n",
            "\n",
            "Using these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\n",
            "\n",
            "INALI: -pasadores: \"ya nts'äza xi mra nts'u̱t'i mi t'e̱ni ko n'a ra t'e̱nga ts'u̱t'a bo̱ja mi thutuabi ra ballesta\".\n",
            "\n",
            "OTS: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Below are examples of orthographic conversions of strings from the INALI standard to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "Examples:\n",
            "\n",
            "1. INALI: r'atsa noya ra sahagún: ndäxjua k'oi florentino. he̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "OTS: r'atsa noya ra sahagún: ndäxkjua k'oi florentino. je̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "\n",
            "2. INALI: nubia ri nt'ode nehe mar'a ya ñ'o̱ho̱ ne ya b'e̱hña ndeznä: ha ra yancuic tlahtolli, r'ayo noya.\n",
            "OTS: nubia ri nt'ode neje mar'a ya ñ'o̱jo̱ ne ya b'e̱jña ndeznä: ja ra yancuic tlahtolli, r'ayo noya.\n",
            "\n",
            "Task:\n",
            "\n",
            "Using these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\n",
            "\n",
            "INALI: cantares mexicanos, biblioteca nacional de méxico, ya nt'ofo 1628 bis, folio 16 v.\n",
            "\n",
            "OTS: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "### OTS → OTQ ###\n",
            "\n",
            "Below are examples of orthographic conversions of strings from the OTS standard (State of Mexico Otomi) to the OTQ standard (Queretaro Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "Examples:\n",
            "\n",
            "1. OTS: r'atsa noya ra sahagún: ndäxkjua k'oi florentino. je̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "OTQ: r'atsa noya ra sahagún: ndäxjua k'oi florentino. he̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "\n",
            "2. OTS: nubia ri nt'ode neje mar'a ya ñ'o̱jo̱ ne ya b'e̱jña ndeznä: ja ra yancuic tlahtolli, r'ayo noya.\n",
            "OTQ: nubia ri nt'ode nehe mar'a ya ñ'o̱ho̱ ne ya b'e̱hña ndeznä: ha ra yancuic tlahtolli, r'ayo noya.\n",
            "\n",
            "Task:\n",
            "\n",
            "Using these examples as a guide, predict the OTQ orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\n",
            "\n",
            "OTS: -pasadores: \"ya nts'äza xi mra nts'u̱t'i mi t'e̱ni ko n'a ra t'e̱nga ts'u̱t'a bo̱kja mi tjutuabi ra ballesta\".\n",
            "\n",
            "OTQ: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Below are examples of orthographic conversions of strings from the OTS standard (State of Mexico Otomi) to the OTQ standard (Queretaro Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\n",
            "\n",
            "Examples:\n",
            "\n",
            "1. OTS: r'atsa noya ra sahagún: ndäxkjua k'oi florentino. je̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "OTQ: r'atsa noya ra sahagún: ndäxjua k'oi florentino. he̱m'i xiii, xe̱ni xiii (versión del náhuatl por ángel ma. garibay k.).\n",
            "\n",
            "2. OTS: nubia ri nt'ode neje mar'a ya ñ'o̱jo̱ ne ya b'e̱jña ndeznä: ja ra yancuic tlahtolli, r'ayo noya.\n",
            "OTQ: nubia ri nt'ode nehe mar'a ya ñ'o̱ho̱ ne ya b'e̱hña ndeznä: ha ra yancuic tlahtolli, r'ayo noya.\n",
            "\n",
            "Task:\n",
            "\n",
            "Using these examples as a guide, predict the OTQ orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\n",
            "\n",
            "OTS: cantares mexicanos, biblioteca nacional de méxico, ya nt'ofo 1628 bis, folio 16 v.\n",
            "\n",
            "OTQ: [Your prediction here]\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdNgYNyg4E0n",
        "outputId": "cbc9124e-2986-4ec8-89df-0a0662919361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_gpt-3.5-turbo_few-shot_OTQ_OTS.tsv'.\n",
            "Total cost: $0.310536 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_gpt-3.5-turbo_few-shot_INALI_OTS.tsv'.\n",
            "Total cost: $0.311397 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_gpt-3.5-turbo_few-shot_OTS_OTQ.tsv'.\n",
            "Total cost: $0.312865 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_gpt-4o_few-shot_OTQ_OTS.tsv'.\n",
            "Total cost: $0.546867 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_gpt-4o_few-shot_INALI_OTS.tsv'.\n",
            "Total cost: $0.543358 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_gpt-4o_few-shot_OTS_OTQ.tsv'.\n",
            "Total cost: $0.551040 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_llama3.1-70b_few-shot_OTQ_OTS.tsv'.\n",
            "Total cost: $0.568151 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_llama3.1-70b_few-shot_INALI_OTS.tsv'.\n",
            "Total cost: $0.569022 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_llama3.1-70b_few-shot_OTS_OTQ.tsv'.\n",
            "Total cost: $0.573941 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_llama3.3-70b_few-shot_OTQ_OTS.tsv'.\n",
            "Total cost: $0.582901 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_llama3.3-70b_few-shot_INALI_OTS.tsv'.\n",
            "Total cost: $0.572079 (logged in costs.txt)\n",
            "\n",
            "191/191\n",
            "Experiment results saved to 'ICL/colab_outputs/oto_llama3.3-70b_few-shot_OTS_OTQ.tsv'.\n",
            "Total cost: $0.580289 (logged in costs.txt)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models = [\n",
        "    (\"gpt-3.5-turbo\", client_gpt),\n",
        "    (\"gpt-4o\", client_gpt),\n",
        "    (\"llama3.1-70b\", client_llama),\n",
        "    (\"llama3.3-70b\", client_llama)\n",
        "]\n",
        "\n",
        "for model, client in models:\n",
        "    run_experiment(\n",
        "        language=\"oto\",\n",
        "        experiment_type=\"few-shot\",\n",
        "        model_name=model,\n",
        "        model_client=client,\n",
        "        test_set=df_test_set,\n",
        "        support_set=df_support_set,\n",
        "        source_column=\"OTQ\",\n",
        "        target_column=\"OTS\",\n",
        "        num_few_shot_examples=10,\n",
        "        instruction_template=\"\"\"Below are examples of orthographic conversions of strings from the OTQ standard (Queretaro Otomi) to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\nExamples:\\n\\n{examples}Task:\\n\\nUsing these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\\n\\n\"\"\",\n",
        "        quiet = True\n",
        "    )\n",
        "\n",
        "    run_experiment(\n",
        "        language=\"oto\",\n",
        "        experiment_type=\"few-shot\",\n",
        "        model_name=model,\n",
        "        model_client=client,\n",
        "        test_set=df_test_set,\n",
        "        support_set=df_support_set,\n",
        "        source_column=\"INALI\",\n",
        "        target_column=\"OTS\",\n",
        "        num_few_shot_examples=10,\n",
        "        instruction_template=\"\"\"Below are examples of orthographic conversions of strings from the INALI standard to the OTS standard (State of Mexico Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\nExamples:\\n\\n{examples}Task:\\n\\nUsing these examples as a guide, predict the OTS orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\\n\\n\"\"\",\n",
        "        quiet = True\n",
        "    )\n",
        "\n",
        "    run_experiment(\n",
        "        language=\"oto\",\n",
        "        experiment_type=\"few-shot\",\n",
        "        model_name=model,\n",
        "        model_client=client,\n",
        "        test_set=df_test_set,\n",
        "        support_set=df_support_set,\n",
        "        source_column=\"OTS\",\n",
        "        target_column=\"OTQ\",\n",
        "        num_few_shot_examples=10,\n",
        "        instruction_template=\"\"\"Below are examples of orthographic conversions of strings from the OTS standard (State of Mexico Otomi) to the OTQ standard (Queretaro Otomi) for the Otomi language. Note that some loanwords retain their original orthography, and certain linguistic phenomena may affect the transformations.\\n\\nExamples:\\n\\n{examples}Task:\\n\\nUsing these examples as a guide, predict the OTQ orthographic standardization for the following sentence. Return only the standardized sentence without any explanation.\\n\\n\"\"\",\n",
        "        quiet = True\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}